{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.llms import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get pdf texts\n",
    "def get_pdf_text(pdf_docs):\n",
    "    text = \"\"\n",
    "    for pdf in pdf_docs:\n",
    "        pdf_reader = PdfReader(pdf)\n",
    "\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get text chunks\n",
    "def get_text_chunks(text):\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len\n",
    "    )\n",
    "\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a vector store if you want through api\n",
    "def get_vectorstore(text_chunks):\n",
    "    \n",
    "    inference_api_key = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "    embeddings = HuggingFaceInferenceAPIEmbeddings(api_key = inference_api_key, model_name=\"hkunlp/instructor-xl\")\n",
    "\n",
    "    vectorstore = FAISS.from_texts(text_chunks, embeddings)\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # without using api\n",
    "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# def get_vectorstore(text_chunks):\n",
    "    \n",
    "#     embeddings = HuggingFaceEmbeddings(model_name=\"hkunlp/instructor-xl\")\n",
    "#     vectorstore = FAISS.from_texts(text_chunks, embeddings)\n",
    "#     return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversation_chain(vectorstore):\n",
    "    \n",
    "    llm = HuggingFaceHub( repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\", model_kwargs={\"temperature\": 0.5, \"max_length\": 64, \"max_new_tokens\":512})\n",
    "\n",
    "    memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True, memory_size=500)\n",
    "    \n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        chain_type='stuff',\n",
    "        retriever=vectorstore.as_retriever(search_kwargs={\"k\": 1}),\n",
    "        memory=memory\n",
    "    )\n",
    "    return conversation_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define chat function\n",
    "def conversation_chat(conversation_chain, query, history):\n",
    "\n",
    "    result = conversation_chain({\"question\": query, \"chat_history\": history})\n",
    "    history.append((query, result[\"answer\"]))\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(user_input):\n",
    "\n",
    "    history = []\n",
    "\n",
    "    # Load PDF documents\n",
    "    pdf_docs = [\"check1.pdf\"]  \n",
    "    \n",
    "    # Get PDF text\n",
    "    raw_text = get_pdf_text(pdf_docs)\n",
    "\n",
    "    # Get text chunks\n",
    "    text_chunks = get_text_chunks(raw_text)\n",
    "\n",
    "    # Create vector store\n",
    "    vectorstore = get_vectorstore(text_chunks)\n",
    "\n",
    "    # creating the chain\n",
    "    conversation_chain = get_conversation_chain(vectorstore)\n",
    "\n",
    "    output = conversation_chat(conversation_chain ,user_input, history)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"What sectors saw the fastest job growth according to the fact sheet?\"\n",
    "output = main(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renewable energy jobs refer to employment opportunities within the renewable energy sector, which includes industries such as wind, solar, hydroelectric, geothermal, and biomass energy. These jobs can range from manufacturing and installing renewable energy systems, to operating and maintaining them, to conducting research and development, and to providing policy and regulatory support. According to the Environmental Entrepreneurs and the U.S. Department of Energy, the clean energy industry, which includes renewable energy, employed over 4 million people in the United States as of 2023. The top states for renewable energy employment were California, Texas, Florida, New York, and Iowa. The electric power generation, transmission, and distribution sector, which includes renewable energy, employed over 600,000 people in the United States as of 2023.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "match = re.findall(r'\\nHelpful Answer: (.*)', output)\n",
    "\n",
    "for item in match:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
