{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.llms import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get pdf texts\n",
    "def get_pdf_text(pdf_docs):\n",
    "    text = \"\"\n",
    "    for pdf in pdf_docs:\n",
    "        pdf_reader = PdfReader(pdf)\n",
    "\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get text chunks\n",
    "def get_text_chunks(text):\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len\n",
    "    )\n",
    "\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a vector store if you want through api\n",
    "def get_vectorstore(text_chunks):\n",
    "    \n",
    "    inference_api_key = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "    embeddings = HuggingFaceInferenceAPIEmbeddings(api_key = inference_api_key, model_name=\"hkunlp/instructor-xl\")\n",
    "\n",
    "    vectorstore = FAISS.from_texts(text_chunks, embeddings)\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # without using api\n",
    "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# def get_vectorstore(text_chunks):\n",
    "    \n",
    "#     embeddings = HuggingFaceEmbeddings(model_name=\"hkunlp/instructor-xl\")\n",
    "#     vectorstore = FAISS.from_texts(text_chunks, embeddings)\n",
    "#     return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the conversation chain\n",
    "def get_conversation_chain(vectorstore):\n",
    "    \n",
    "    llm = HuggingFaceHub( repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\", model_kwargs={\"temperature\": 0.5, \"max_length\": 64, \"max_new_tokens\":512})\n",
    "    \n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        chain_type='stuff',\n",
    "        retriever=vectorstore.as_retriever(search_kwargs={\"k\": 1}),\n",
    "    )\n",
    "    return conversation_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define chat function\n",
    "\n",
    "def conversation_chat(conversation_chain, query, history):\n",
    "\n",
    "    result = conversation_chain({\"question\": query})\n",
    "    history.append((query, result[\"answer\"]))\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function\n",
    "\n",
    "def main(pdf_docs, user_input):\n",
    "\n",
    "    # Load PDF documents here \n",
    "    \n",
    "    # Get PDF text\n",
    "    raw_text = get_pdf_text(pdf_docs)\n",
    "\n",
    "    # Get text chunks\n",
    "    text_chunks = get_text_chunks(raw_text)\n",
    "\n",
    "    # Create vector store\n",
    "    vectorstore = get_vectorstore(text_chunks)\n",
    "\n",
    "    # creating the chain\n",
    "    conversation_chain = get_conversation_chain(vectorstore)\n",
    "\n",
    "    output = conversation_chat(conversation_chain ,user_input)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'check1.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# ask the question here \u001b[39;00m\n\u001b[0;32m      5\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat sectors saw the fastest job growth according to the fact sheet?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(user_input)\u001b[0m\n\u001b[0;32m      6\u001b[0m pdf_docs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck1.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Get PDF text\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m raw_text \u001b[38;5;241m=\u001b[39m \u001b[43mget_pdf_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_docs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Get text chunks\u001b[39;00m\n\u001b[0;32m     12\u001b[0m text_chunks \u001b[38;5;241m=\u001b[39m get_text_chunks(raw_text)\n",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m, in \u001b[0;36mget_pdf_text\u001b[1;34m(pdf_docs)\u001b[0m\n\u001b[0;32m      3\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pdf \u001b[38;5;129;01min\u001b[39;00m pdf_docs:\n\u001b[1;32m----> 5\u001b[0m     pdf_reader \u001b[38;5;241m=\u001b[39m \u001b[43mPdfReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m pdf_reader\u001b[38;5;241m.\u001b[39mpages:\n\u001b[0;32m      8\u001b[0m         text \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m page\u001b[38;5;241m.\u001b[39mextract_text()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\PyPDF2\\_reader.py:317\u001b[0m, in \u001b[0;36mPdfReader.__init__\u001b[1;34m(self, stream, strict, password)\u001b[0m\n\u001b[0;32m    311\u001b[0m     logger_warning(\n\u001b[0;32m    312\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPdfReader stream/file object is not in binary mode. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt may not be read correctly.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    314\u001b[0m         \u001b[38;5;18m__name__\u001b[39m,\n\u001b[0;32m    315\u001b[0m     )\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream, (\u001b[38;5;28mstr\u001b[39m, Path)):\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[0;32m    318\u001b[0m         stream \u001b[38;5;241m=\u001b[39m BytesIO(fh\u001b[38;5;241m.\u001b[39mread())\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(stream)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'check1.pdf'"
     ]
    }
   ],
   "source": [
    "# enter the docs here\n",
    "docs = [\"dataset/FactSheet_Climate_Jobs_2024\"]\n",
    "\n",
    "# ask the question here \n",
    "user_input = \"What sectors saw the fastest job growth according to the fact sheet?\"\n",
    "output = main(docs, user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renewable energy jobs refer to employment opportunities within the renewable energy sector, which includes industries such as wind, solar, hydroelectric, geothermal, and biomass energy. These jobs can range from manufacturing and installing renewable energy systems, to operating and maintaining them, to conducting research and development, and to providing policy and regulatory support. According to the Environmental Entrepreneurs and the U.S. Department of Energy, the clean energy industry, which includes renewable energy, employed over 4 million people in the United States as of 2023. The top states for renewable energy employment were California, Texas, Florida, New York, and Iowa. The electric power generation, transmission, and distribution sector, which includes renewable energy, employed over 600,000 people in the United States as of 2023.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "match = re.findall(r'\\nHelpful Answer: (.*)', output)\n",
    "\n",
    "for item in match:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
